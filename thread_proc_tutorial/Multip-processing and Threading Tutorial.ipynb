{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Threading and Multiprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With threading and multiprocessing you can run code in paralell and speed up the performance of your code. \n",
    "\n",
    "It is important to understand the difference between a process and a thread and the advantages and disadvantages of both. \n",
    "\n",
    "How and threads are limited by the Global Interpreter Lock (GIL, which we cover here) and how we can easily use the build threading and multiprocessing modules in Python to create to multiple threads or processes. \n",
    "\n",
    "## Difference between a process and thread\n",
    "\n",
    "A process is an 'instance' of a program. So if you run a Firefox browser, that's one process. You could start another browser, which would be two processes. Likewise, one Python interpreter is one process. \n",
    "\n",
    "A thread on the other hand is an 'entity' within a process. Processes can have multiple threads inside. \n",
    "\n",
    "## Processes\n",
    "\n",
    "Processes take advantage of multiple CPUs and cores, so you can execute your code on multiple CPUs in parellel. Processes have a sperate memory space, and it is not shared between processes. And they are great for CPU bound processing so this means for example if you have a large amount data and have to do a lot of exansive computations on them. With multi-processing you can process the data on different CPUs and this way speed up your code's execution. A new process is started independtly from other processes and processes are easily 'interuptable' and 'killable' and there's one GIL for each process so this avoids the GIL limitation. \n",
    "\n",
    "### Disdavantages of processes\n",
    "\n",
    "A process is heavyweight, so it takes a lot of memory. Starting a process is slower than starting a thread. And since processes have a seperate space then memory sharing is not so easy, so the so called 'interprocess communication' is more complicated. \n",
    "\n",
    "## Threads \n",
    "\n",
    "A thread is an entity in a process that can be scheduled for execution. It's also known as a 'lightweight process' and a process can spawn multiple threads. All threads within a process share the same memory and they are lightweight so starting a thread is faster than starting a process. And they are great for input/output (I/O) tasks when your program is  interacting with a slower devices like a hard-drive or a network connection, then with threading your program can use the time waiting for the these devices and intelligently switch to other threads and do the processing in the mean time. This is how you can speed up your code with threading. \n",
    "\n",
    "### Disadvantages of threading\n",
    "\n",
    "In Python threading is limited by the GIL, which allows only one thread at a time so there is no actual paralell computation going on in multi-threading. So threading has no effect for CPU bound tasks and they are not interuptable and killable. Be careful with memory leaks. Since a thread share the same memory you have to be careful with 'race conditions' \n",
    "\n",
    "#### What are race conditions\n",
    "\n",
    "Race conditions occurs when two more threads want to modify the same variable at the same time. Easily causes bugs or crashes. \n",
    "\n",
    "#### What are memory leaks?\n",
    "\n",
    "A memory leak in Python is when Python interpreter incorrectly manages memory in a way that memory which is no longer needed is not released. \n",
    "\n",
    "#### What is the GIL?\n",
    "\n",
    "The GIL is the Global Interpreter Lock is a lock in Python that allows only one thread at a time to execute. This is very contraversial in the Python Community. It is needed because in CPython (which is the standard implementation of Python from python.org) there is a memory management which is not thread-safe. In CPython there is a technique which is called 'reference counting' which is used for memory management. Objects created in Python have a refence count variable that keeps track of the number of references that point to the object. And when this count reaches 0 the memory occupied by the object can be released. The problem in multi-threading is that this reference count variable need protection from race conditions where two threads increase or decrease the values simultaneously. When this happens it can either can cause leaked memory which is never released or it can incorrectly release the memory while a reference to the object still exists. So this is the reason the GIL exists in Python. There are a couple of ways to avoid the GIL if you want to use paralell computing, is to use multi-processing, or use a different a different 'free-threaded' Python implemnetation, like Jython or Iron-Python. Or use Python as a wrapper for third-party libraries like Numpy or SciPy modules which are basically Python wrappers for that then call code which is executed in C/C++. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code for Multi-processing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n",
      "End main\n"
     ]
    }
   ],
   "source": [
    "from multiprocessing import Process\n",
    "import os\n",
    "import time\n",
    "\n",
    "#create a list to store processes\n",
    "processes = []\n",
    "\n",
    "# define number of processes\n",
    "num_processes = os.cpu_count()\n",
    "\n",
    "print(num_processes)\n",
    "\n",
    "#define function to be used in processes\n",
    "def square_numbers():\n",
    "    for i in range(100):\n",
    "        i * i\n",
    "        time.sleep(0.5)\n",
    "\n",
    "#create processes\n",
    "for i in range(num_processes):\n",
    "    # spawn new process\n",
    "    p = Process(target=square_numbers)\n",
    "    processes.append(p)\n",
    "    \n",
    "#start processes\n",
    "for p in processes:\n",
    "    p.start()\n",
    "    \n",
    "#join processes\n",
    "for p in processes:\n",
    "    p.join()\n",
    "    #wait for all processes are finished and block the main thread\n",
    "    \n",
    "print('End main')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code for threading\n",
    "\n",
    "\n",
    "Setting up the threading module in exactly the same way as the multi-processing module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n",
      "End main\n"
     ]
    }
   ],
   "source": [
    "from threading import Thread\n",
    "import os\n",
    "import time\n",
    "\n",
    "#create a list to store processes\n",
    "threads = []\n",
    "\n",
    "# define number of processes\n",
    "num_threads = 8\n",
    "\n",
    "print(num_threads)\n",
    "\n",
    "#define function to be used in threads\n",
    "def square_numbers():\n",
    "    for i in range(100):\n",
    "        i * i\n",
    "        time.sleep(0.5)\n",
    "\n",
    "#create threads\n",
    "for i in range(num_threads):\n",
    "    # spawn new thread\n",
    "    t = Thread(target=square_numbers)\n",
    "    threads.append(t)\n",
    "    \n",
    "#start threads\n",
    "for t in threads:\n",
    "    t.start()\n",
    "    \n",
    "#join threads\n",
    "for t in threads:\n",
    "    t.join()\n",
    "    #wait for all threads are finished and block the main thread\n",
    "    \n",
    "print('End main')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create and start multple threads and share Data between threads \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start value:  0\n",
      "End value:  1\n",
      "End main\n"
     ]
    }
   ],
   "source": [
    "from threading import Thread\n",
    "import time\n",
    "\n",
    "# simulate a database\n",
    "database_value = 0 \n",
    "\n",
    "def increase():\n",
    "    global database_value\n",
    "    \n",
    "    #simulating database access\n",
    "    local_copy = database_value\n",
    "    local_copy +=1\n",
    "    time.sleep(0.1)\n",
    "    database_value = local_copy\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    \n",
    "    # print start value \n",
    "    print('Start value: ', database_value)\n",
    "    \n",
    "    #Create the threads\n",
    "    thread1 = Thread(target=increase)\n",
    "    thread2 = Thread(target=increase)\n",
    "    \n",
    "    #Start the threads\n",
    "    thread1.start()\n",
    "    thread2.start()\n",
    "    \n",
    "    #Join the threads\n",
    "    thread1.join()\n",
    "    thread2.join()\n",
    "    \n",
    "    print(\"End value: \", database_value)\n",
    "    \n",
    "    print('End main')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see the outputs for this script are:\n",
    "    \n",
    "- Start value:  0\n",
    "- End value:  1\n",
    "- End main\n",
    "\n",
    "\n",
    "But if the function has been applied twice, it the *End Value should be 2*. It is still 1 because a 'race condition' has been created.   threads try to access the same variable at the same time, causing a bug.\n",
    "Let's step through this program to see why the bug is occuring\n",
    "\n",
    "### Step through - 'debugging' the problem\n",
    "\n",
    "In our `increase` function, there is a `time.sleep` method. During the running of `thread1` the waiting time causes the programme to intelligently `thread2`, which then accesses `database_value` and copies it to `local_copy`. At this point `thread2` also has a local copy which is 0 then increases it to 1. Then again we hit the `time.sleep` method, causing the program to switch back to `thread1`. Finally `thread1` finishes by copying `local_copy` (which has the value 1) to `database_value` (which now becomes 1), and `thread2` does exactly the same, using its `local_copy` (which is also 1)!  We have to do something to avoid this occuring. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using locks to prevent race conditions\n",
    "\n",
    "So how do we prevent race conditions? We use a lock, which can be imported from the threading module. \n",
    "\n",
    "\n",
    "`from threading import Lock`\n",
    "\n",
    "and create a lock\n",
    "\n",
    "`lock = Lock`\n",
    "\n",
    "and this must be be supplied to whichever function is the `target` of the thread as an argument. \n",
    "\n",
    "`def whatever_function(lock):\n",
    "    pass`\n",
    "    \n",
    "So in our case we are supplying it to `increase`.\n",
    "    \n",
    "As `lock` is an argument, we must supply it *as a tuple* to the 'Thread' method when creating a thread with `args=(lock,)`. As the tuple supplied only has one element in it the we need a comma to show the rest of the tuple is empty. \n",
    "\n",
    "Inside the function definition, we also need to use `lock.acquire()` which is one of only two methods of `Lock`, the other is supplied after the values of variables are modified, is `lock.release`. Our function definition will therefore become \n",
    "\n",
    "`def increase(lock):\n",
    "    global database_value\n",
    "    \n",
    "    #acquire a lock before manipulating variables\n",
    "    lock.acquire()\n",
    "    \n",
    "    #simulating database access\n",
    "    local_copy = database_value\n",
    "    local_copy +=1\n",
    "    time.sleep(0.1)\n",
    "    database_value = local_copy\n",
    "\n",
    "    #release the lock after manipulating variables\n",
    "    lock.release()`\n",
    "    \n",
    "Which will release the lock - never forget to do this otherwise the program will get stuck. \n",
    "\n",
    "Another way to achieve this is with a context manager (recommended):\n",
    "\n",
    "'with lock:\n",
    "    #do something`\n",
    "    \n",
    " Then we don't need the `lock.release()`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start value:  0\n",
      "End value:  2\n",
      "End main\n"
     ]
    }
   ],
   "source": [
    "from threading import Thread, Lock\n",
    "import time\n",
    "\n",
    "# simulate a database\n",
    "database_value = 0 \n",
    "\n",
    "def increase(lock):\n",
    "    global database_value\n",
    "    \n",
    "    #acquire a lock before manipulating variables\n",
    "    lock.acquire()\n",
    "    \n",
    "    #simulating database access\n",
    "    local_copy = database_value\n",
    "    local_copy +=1\n",
    "    time.sleep(0.1)\n",
    "    database_value = local_copy\n",
    "\n",
    "    #release the lock after manipulating variables\n",
    "    lock.release()\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    \n",
    "    #create a Lock\n",
    "    lock = Lock()\n",
    "    \n",
    "    # print start value \n",
    "    print('Start value: ', database_value)\n",
    "    \n",
    "    #Create the threads\n",
    "    thread1 = Thread(target=increase, args=(lock,))\n",
    "    thread2 = Thread(target=increase, args=(lock,))\n",
    "    \n",
    "    #Start the threads\n",
    "    thread1.start()\n",
    "    thread2.start()\n",
    "    \n",
    "    #Join the threads\n",
    "    thread1.join()\n",
    "    thread2.join()\n",
    "    \n",
    "    print(\"End value: \", database_value)\n",
    "    \n",
    "    print('End main')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the lock was successful at helping us to avoid race conditions and achieve the right answer.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to use queues \n",
    "\n",
    "Next we will use queues to make thread-safe and process-safe data exchanges. They are excellent for data processing in multi-processing and threading environments. We have to import queue. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from queue import Queue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A queue is a linear data structure that follow FIFO, or first in first out principle. It's like a first come first served situation when a line of customers forms. \n",
    "\n",
    "We need to intiate the queue with:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "queue = Queue()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and then we put elements in the queue:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "queue.put(1)\n",
    "queue.put(2)\n",
    "queue.put(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So the queue order will be 1 then 2 then 3. \n",
    "\n",
    "To get and remove the first item, we can use 'queue.get()', so :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "first = queue.get()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Printing `first` will yield the first item in the queue. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "print(first)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the queue only has 2 and 3 in it, as 1 has been retrieved and removed. \n",
    "\n",
    "When you are done processing the items in the queue you should run `queue.task_done()` \n",
    "\n",
    "`queue.join()` method blocks until all items have been processed in the queue which is similar to `thread.join()` which we used before and with which we blocked the main thread and forced it to wait until all the threads were finished. \n",
    "\n",
    "# Using Daemon processes \n",
    "\n",
    "Define the number of threads and create them with:\n",
    "\n",
    "```python\n",
    "q = Queue()\n",
    "    num_threads  = 10 \n",
    " ```\n",
    "and make it a daemon process with `thread.deamon = True`.\n",
    " \n",
    "```python \n",
    "for i in range(num_threads):\n",
    "    thread = Thread(target=worker, args=(q,))\n",
    "    thread.start()\n",
    "    thread.deamon = True\n",
    " ```\n",
    "\n",
    "in a dummy function `worker` we will create an infinite loop with `while True:` and use `value = q.get()` to get the first item from the queue in a thread-safe  way. \n",
    "\n",
    "We will also create 10 threads. Within `for i in range(num_threads):` we will use `q.put()` which is also thread-safe. No other thread can write at the same time until the queue position is finished. \n",
    "\n",
    "We will provide the function with the lock too, to prevent the possibility of confused threads. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thread-220 got value 1 \n",
      "Thread-224 got value 5 \n",
      "Thread-221 got value 2 \n",
      "Thread-226 got value 8 \n",
      "Thread-227 got value 7 \n",
      "\n",
      "End Main\n",
      "\n",
      "\n",
      "\n",
      "Thread-224 got value 6 \n",
      "\n",
      "Thread-226 got value 9 \n",
      "\n",
      "Thread-221 got value 3 \n",
      "\n",
      "Thread-224 got value 10 \n",
      "\n",
      "\n",
      "Thread-221 got value 4 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from threading import current_thread\n",
    "\n",
    "def worker(q, lock):\n",
    "    while True:\n",
    "        value = q.get()\n",
    "        \n",
    "        #process q\n",
    "        \n",
    "        print(f'{current_thread().name} got value {value} \\n')\n",
    "        q.task_done()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    \n",
    "    #create the queue\n",
    "    q = Queue()\n",
    "    \n",
    "    #create the lock\n",
    "    lock = Lock()\n",
    "    \n",
    "    num_threads  = 10 \n",
    "        \n",
    "    for i in range(num_threads):\n",
    "        thread = Thread(target=worker, args=(q, lock))\n",
    "        thread.start()\n",
    "        thread.deamon = True\n",
    "\n",
    "    for i in range(1, 11):\n",
    "        q.put(i)\n",
    "\n",
    "    q.join()\n",
    "    \n",
    "    print('End Main')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that threads of different names are given the values. They are not sequential but all of the values from the queue get processed. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Why are we using a daemon thread?\n",
    "\n",
    "From the [Python Documentation](https://docs.python.org/2/library/threading.html#thread-objects)\n",
    ">  The significance of this flag is that the entire Python program exits when only daemon threads are left. The initial value is inherited from the creating thread.\n",
    "\n",
    "By setting threads as daemon threads you can let them run and forget about them, and when your program quits and remaining daemon threads are killed automatically. Some threads that run background tasks are only useful when the main program is running so it's okay to kill them off once the other, main or non-daemon, threads have exited. By flagging them as `daemon=True` they are automatically killed when the main thread is exited. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
